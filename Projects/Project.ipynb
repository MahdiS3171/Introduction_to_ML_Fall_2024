{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q_1"
      ],
      "metadata": {
        "id": "hniNtD-Zew1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "aY3-XWyHghIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True)\n",
        "\n",
        "X_train_torch = trainset.data\n",
        "Y_train_torch = trainset.targets\n",
        "\n",
        "X_test_torch = testset.data\n",
        "Y_test_torch = testset.targets\n",
        "\n",
        "\n",
        "\n",
        "# Training Images:\n",
        "X_train = X_train_torch.numpy()\n",
        "# Training Labels:\n",
        "Y_train = Y_train_torch.numpy()\n",
        "\n",
        "# Test Images:\n",
        "X_test = X_test_torch.numpy()\n",
        "# Test Labels:\n",
        "Y_test = Y_test_torch.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0Z15GkFglKD",
        "outputId": "f7b0a847-6159-4087-814c-fe2b06093332"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 42.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.24MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 10.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 3.89MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Binarize the data by applying a threshold\n",
        "threshold = 128  # Pixel values above 128 will be set to 1, others to 0\n",
        "x_train_binary = (x_train > threshold).astype(np.uint32)\n",
        "x_test_binary = (x_test > threshold).astype(np.uint32)\n",
        "x_train_binary = x_train_binary.reshape(-1, 28 * 28)\n",
        "x_test_binary = x_test_binary.reshape(-1, 28 * 28)"
      ],
      "metadata": {
        "id": "Fyoczl3mgr6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display a few samples from the binary dataset\n",
        "def show_samples(samples, nrows=2, ncols=5):\n",
        "    fig, axes = plt.subplots(nrows, ncols, figsize=(10, 5))\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        # Reshape each sample back to (28, 28) for display\n",
        "        ax.imshow(samples[i].reshape(28, 28), cmap='binary')\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "-Lk-RDaWgtDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "id": "AgNBDeGkemAG",
        "outputId": "279a74c0-ecff-4fec-cb37-2d1b12427fa6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 10 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA94AAAGnCAYAAABB348LAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAOWElEQVR4nO3d0ZLbthmAUW/H7//KykWbJnYqVuLiowDwnMtk7NXKBKlvoPnx9Xg8Hj8AAACAxL8+/QIAAABgZ8IbAAAAQsIbAAAAQsIbAAAAQsIbAAAAQsIbAAAAQsIbAAAAQsIbAAAAQsIbAAAAQsIbAAAAQsIbAAAAQsIbAAAAQsIbAAAAQsIbAAAAQsIbAAAAQsIbAAAAQsIbAAAAQsIbAAAAQsIbAAAAQsIbAAAAQsIbAAAAQsIbAAAAQsIbAAAAQsIbAAAAQsIbAAAAQsIbAAAAQsIbAAAAQsIbAAAAQsIbAAAAQsIbAAAAQsIbAAAAQsIbAAAAQsIbAAAAQsIbAAAAQj8//QIACl9fX8P+rsfjMezvAgDgfux4AwAAQEh4AwAAQEh4AwAAQEh4AwAAQEh4AwAAQMhU882dmex8NMHZpGhmMvJ6PPtzXMfwOmuJXY3+vAXsx443AAAAhIQ3AAAAhIQ3AAAAhIQ3AAAAhIQ3AAAAhEw1BwCAF1x1mgawH+E9wG434d1+H9bnmgQAYGW+ag4AAAAh4Q0AAAAh4Q0AAAAh4Q0AAAAh4Q0AAACh2041NyX5x4/H4/HplwD/NcOafLYmjl7bs/9nfX2Gf485zLCeAe7gqvvtmefo0Wu743PZjjcAAACEhDcAAACEhDcAAACEhDcAAACEhDcAAACEbjvVHIA1mZgNlEbfY+44vZmxZnjujX4NdzyFRHgDw83wgPg0R2gAAPAnXzUHAACAkPAGAACAkPAGAACAkPAGAACAkPAGAACA0G2nmj+bKnxmEvHMx06YLs3OjtbKyGv/qp8DKzlz7Zvoz0yuek7Aq2a+JmfunVXY8QYAAICQ8AYAAICQ8AYAAICQ8AYAAICQ8AYAAIDQbaeaAwCwNydPMBvTwe9LeP/mqot3t5/DPV31gebMdezaBwBgFr5qDgAAACHhDQAAACHhDQAAACHhDQAAACHhDQAAACFTzT/kaBq0aczMZObJ5at69p7e6T0AWJH7NH+342ekkb+T9fIrO94AAAAQEt4AAAAQEt4AAAAQEt4AAAAQEt4AAAAQMtUcgCmdmaxqgup4V03the8wiZkduPb2JrwHOFokPrCwCh9aAACg4avmAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEDLVPPZsuvPRBGlH6LAK1x3sYfQJHO4NwE5WPPnlypOV3PNfY8cbAAAAQsIbAAAAQsIbAAAAQsIbAAAAQsIbAAAAQqaaA8AHXTl5FlZm+j4rGXl9zfCcsF6+T3h/yNHFe2ZxPfszFgl/N8ONGwAA7sZXzQEAACAkvAEAACAkvAEAACAkvAEAACAkvAEAACBkqvmEnk0iHznt/MzP555cD6zE5P7xa9Z7ytVcc+zAdczv7HgDAABASHgDAABASHgDAABASHgDAABASHgDAABASHgDAABAyHFiCzlzRMzoI8gcLcUdjT4SxDp6zVX3vJH828Jrrlqr1iQjjDzqd+TPP/Lp5yH/ZMcbAAAAQsIbAAAAQsIbAAAAQsIbAAAAQsIbAAAAQqaaA/zHyAmgJul+hvf9HNNvAd634zNnx99pFna8AQAAICS8AQAAICS8AQAAICS8AQAAICS8AQAAICS8AQAAIOQ4sYU47gW+b/Q6cuwGd+Xa5xVXfXZxPQKzs+MNAAAAIeENAAAAIeENAAAAIeENAAAAIeENAAAAIVPNP8SEcmiNXGOm5QJ8nnsxsDI73gAAABAS3gAAABAS3gAAABAS3gAAABAS3gAAABAS3gAAABBynFhs5mPDHMvBK46u4ZHX0AxrxZoAeN8M92+A2dnxBgAAgJDwBgAAgJDwBgAAgJDwBgAAgJDwBgAAgJCp5m+YeWqnacx8wsxr4hlrBQCAq9nxBgAAgJDwBgAAgJDwBgAAgJDwBgAAgJDwBgAAgJDwBgAAgNDWx4mteNTRjx+OO4JXWSvwOUfPWGuT73D9ADuy4w0AAAAh4Q0AAAAh4Q0AAAAh4Q0AAAAh4Q0AAAChZaaarzqh/BkTO/mEM9fdVWvPmgAAYFd2vAEAACAkvAEAACAkvAEAACAkvAEAACAkvAEAACAkvAEAACA03XFiKx4b5hgkdub6hv0drfMVn8sAd3f2vv7s//k8+H12vAEAACAkvAEAACAkvAEAACAkvAEAACAkvAEAACD09TCiDgAA4BZGn1YhJ19jxxsAAABCwhsAAABCwhsAAABCwhsAAABCwhsAAABCwhsAAABCPz/9AgAAALjG0fFfo48a4y92vAEAACAkvAEAACAkvAEAACAkvAEAACAkvAEAACBkqjkAAACHE8/5HjveAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEPr56RcAAAAAR76+vt7+M4/HI3gl5whv4FJnbprPzHQzBQCAZ3zVHAAAAELCGwAAAELCGwAAAELCGwAAAELCGwAAAEKmmgPAYkaeDnAlJxFQebYmXHOwllWfb6+w4w0AAAAh4Q0AAAAh4Q0AAAAh4Q0AAAAh4Q0AAAAhU80BYJCdp7GOcPT+mD7N/2N9wT5GrudVnh/Ce0IzP1hWubABAABm4avmAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEDLVPDbzhHIAznFvBwDeYccbAAAAQsIbAAAAQsIbAAAAQsIbAAAAQsIbAAAAQqaaA8CbHo/H//zvpp0DcKVnz51nz6mVrf47Ce83zPyB6syFOPPvAwAAsAtfNQcAAICQ8AYAAICQ8AYAAICQ8AYAAICQ8AYAAICQqeYLWX2EPsDudrxPOwED4LNWvQ+fed07Pkf/ZMcbAAAAQsIbAAAAQsIbAAAAQsIbAAAAQsIbAAAAQsIbAAAAQo4T+80M4/p3HqMPz67vM2vv6M9YRwAAzMKONwAAAISENwAAAISENwAAAISENwAAAISENwAAAIRMNf+NScgA3M1VJ3p4xnI1p1+wkhlOVzpj1dd9NTveAAAAEBLeAAAAEBLeAAAAEBLeAAAAEBLeAAAAEDLVHAA2YroswH1cNZ1/9LPljqcKCO/N+QAGAADwWb5qDgAAACHhDQAAACHhDQAAACHhDQAAACHhDQAAACFTzQHgArudMnHHo2AAvmu3Z8ERz4lf2fEGAACAkPAGAACAkPAGAACAkPAGAACAkPAGAACAkKnmAPCmO02lBeB9qz4nVn3dKxDesRUvXqP/AQAAxvFVcwAAAAgJbwAAAAgJbwAAAAgJbwAAAAgJbwAAAAiZav6GFSeUAwAA483QBjO8BicivcaONwAAAISENwAAAISENwAAAISENwAAAISENwAAAISENwAAAIS+Hua//+LMSP6r3kLHBbCzq65v1zB3NnKdWUvMZObPb6zv0/fOGRrgDGvsV3a8AQAAICS8AQAAICS8AQAAICS8AQAAICS8AQAAIPTz0y+gtOoEwJlft6mhAOt6dj+e+bkDcIWZP+Me/Rz373XY8QYAAICQ8AYAAICQ8AYAAICQ8AYAAICQ8AYAAICQ8AYAAIDQFseJjRyjf9WxAKNH/8/8ulf892FfR9ej6wsA7ulOnwHu9LvOxI43AAAAhIQ3AAAAhIQ3AAAAhIQ3AAAAhIQ3AAAAhLaYan7GyGl+q04oP+PMazvz/sz8HtA4+jcfvcbgrqwl+Muz9eAzCLNx796DHW8AAAAICW8AAAAICW8AAAAICW8AAAAICW8AAAAICW8AAAAILXOc2Ogx+p8ey3+noyru9LsCc7rTsYaffr7BKlZd4/AK1/d87HgDAABASHgDAABASHgDAABASHgDAABASHgDAABAaJmp5jMzNRBgDiMnepsO/m+ecQDX8NzZmx1vAAAACAlvAAAACAlvAAAACAlvAAAACAlvAAAACAlvAAAACC1znNiZ40yORvI7HgXW8Wy9OnYDxvBMBLjG6M8u7t/rsOMNAAAAIeENAAAAIeENAAAAIeENAAAAIeENAAAAoWWmmp9hyh/AvZiA79kHMLOje/SzZ5X7+h7seAMAAEBIeAMAAEBIeAMAAEBIeAMAAEBIeAMAAEBIeAMAAEBo6+PEgL05XoNXnblWRh9B5noF4IjnxN7seAMAAEBIeAMAAEBIeAMAAEBIeAMAAEBIeAMAAEDo62F8HgAAAGTseAMAAEBIeAMAAEBIeAMAAEBIeAMAAEBIeAMAAEBIeAMAAEBIeAMAAEBIeAMAAEBIeAMAAEBIeAMAAEBIeAMAAEBIeAMAAEBIeAMAAEBIeAMAAEBIeAMAAEBIeAMAAEBIeAMAAEBIeAMAAEBIeAMAAEBIeAMAAEBIeAMAAEBIeAMAAEBIeAMAAEBIeAMAAEBIeAMAAEBIeAMAAEBIeAMAAEBIeAMAAEBIeAMAAEDoD81Z/Mm8h95aAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "show_samples(x_train_binary[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q_2"
      ],
      "metadata": {
        "id": "BK2_hMXwgx2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RBM:\n",
        "    def __init__(self, n_visible, n_hidden):\n",
        "      self.n_visible = n_visible\n",
        "      self.n_hidden = n_hidden\n",
        "      self.W = np.random.normal(0, 0.01, (n_visible, n_hidden))  # Gaussian init\n",
        "      self.v_bias = np.zeros(n_visible)\n",
        "      self.h_bias = np.zeros(n_hidden)\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def sample(self, prob):\n",
        "        return (np.random.rand(*prob.shape) < prob).astype(np.float32)\n",
        "\n",
        "    def gibbs_sampling(self, v, k):\n",
        "        for _ in range(k):\n",
        "            h_prob = self.sigmoid(np.dot(v, self.W) + self.h_bias)\n",
        "            h_sample = self.sample(h_prob)\n",
        "            v_prob = self.sigmoid(np.dot(h_sample, self.W.T) + self.v_bias)\n",
        "            v = self.sample(v_prob)\n",
        "        return v\n",
        "\n",
        "    def contrastive_divergence(self, v, k, lr):\n",
        "        v_neg = v.copy()  # Initialize negative visible states\n",
        "        for _ in range(k):\n",
        "            h_prob = self.sigmoid(np.dot(v_neg, self.W) + self.h_bias)  # Hidden probabilities\n",
        "            h_state = (h_prob > np.random.rand(*h_prob.shape)).astype(np.float32)  # Sample h\n",
        "            v_prob_neg = self.sigmoid(np.dot(h_state, self.W.T) + self.v_bias)  # Reconstruct v\n",
        "            v_neg = (v_prob_neg > np.random.rand(*v_prob_neg.shape)).astype(np.float32)  # Sample v\n",
        "\n",
        "        # Update weights and biases\n",
        "        h_prob = self.sigmoid(np.dot(v, self.W) + self.h_bias)  # Positive phase\n",
        "        h_prob_neg = self.sigmoid(np.dot(v_neg, self.W) + self.h_bias)  # Negative phase\n",
        "\n",
        "        positive_grad = np.dot(v.T, h_prob)\n",
        "        negative_grad = np.dot(v_neg.T, h_prob_neg)\n",
        "        self.W += lr * (positive_grad - negative_grad) / v.shape[0]\n",
        "        self.v_bias += lr * np.mean(v - v_neg, axis=0)\n",
        "        self.h_bias += lr * np.mean(h_prob - h_prob_neg, axis=0)\n",
        "\n",
        "        return v_neg  # Return the negative visible states\n",
        "\n",
        "    def train(self, data, epochs=10, k=1, lr=0.01, batch_size=64):\n",
        "        for epoch in range(epochs):\n",
        "            np.random.shuffle(data)\n",
        "            epoch_loss = 0\n",
        "            for batch_start in range(0, len(data), batch_size):\n",
        "                batch = data[batch_start:batch_start + batch_size]\n",
        "                v_neg = self.contrastive_divergence(batch, k, lr)\n",
        "                epoch_loss += np.mean((batch - v_neg) ** 2)  # Reconstruction loss\n",
        "            print(f\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss / len(data):.4f}\")\n",
        "\n",
        "    def generate_samples(self, n_samples=10, k=1):\n",
        "        samples = np.random.rand(n_samples, self.n_visible)\n",
        "        samples = self.gibbs_sampling(samples, k)\n",
        "        return samples"
      ],
      "metadata": {
        "id": "eo_bdVargxQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], -1)  # Flatten to (num_samples, n_visible)\n",
        "# Initialize and train RBM for different values of k\n",
        "n_visible = x_train.shape[1]\n",
        "n_hidden = 128\n",
        "k_values = [1, 3, 5]\n",
        "rbms = {}\n",
        "\n",
        "for k in k_values:\n",
        "    print(f\"Training RBM with k={k}\")\n",
        "    rbm = RBM(n_visible, n_hidden)\n",
        "    rbm.train(x_train, epochs=50, k=10, lr=0.01, batch_size=128)\n",
        "    rbms[k] = rbm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "IsRPseBijAmX",
        "outputId": "77563f38-0d2c-44d2-eb76-55b4419b12c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training RBM with k=1\n",
            "Epoch 1/50, Loss: 0.0018\n",
            "Epoch 2/50, Loss: 0.0013\n",
            "Epoch 3/50, Loss: 0.0011\n",
            "Epoch 4/50, Loss: 0.0011\n",
            "Epoch 5/50, Loss: 0.0010\n",
            "Epoch 6/50, Loss: 0.0010\n",
            "Epoch 7/50, Loss: 0.0010\n",
            "Epoch 8/50, Loss: 0.0009\n",
            "Epoch 9/50, Loss: 0.0009\n",
            "Epoch 10/50, Loss: 0.0009\n",
            "Epoch 11/50, Loss: 0.0009\n",
            "Epoch 12/50, Loss: 0.0009\n",
            "Epoch 13/50, Loss: 0.0009\n",
            "Epoch 14/50, Loss: 0.0008\n",
            "Epoch 15/50, Loss: 0.0008\n",
            "Epoch 16/50, Loss: 0.0008\n",
            "Epoch 17/50, Loss: 0.0008\n",
            "Epoch 18/50, Loss: 0.0008\n",
            "Epoch 19/50, Loss: 0.0008\n",
            "Epoch 20/50, Loss: 0.0008\n",
            "Epoch 21/50, Loss: 0.0008\n",
            "Epoch 22/50, Loss: 0.0008\n",
            "Epoch 23/50, Loss: 0.0008\n",
            "Epoch 24/50, Loss: 0.0008\n",
            "Epoch 25/50, Loss: 0.0008\n",
            "Epoch 26/50, Loss: 0.0008\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-53005043c14a>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training RBM with k={k}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mrbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRBM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_visible\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mrbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mrbms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrbm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-44-bb9ff1b4746f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data, epochs, k, lr, batch_size)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch_start\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_start\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0mv_neg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrastive_divergence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m                 \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mv_neg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Reconstruction loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss / len(data):.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-44-bb9ff1b4746f>\u001b[0m in \u001b[0;36mcontrastive_divergence\u001b[0;34m(self, v, k, lr)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mv_neg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Initialize negative visible states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mh_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_neg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh_bias\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Hidden probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mh_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh_prob\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mh_prob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Sample h\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mv_prob_neg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_bias\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Reconstruct v\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate and visualize samples\n",
        "def show_generated_samples(rbm, k, n_samples=10):\n",
        "    print(f\"Generated samples for k={k}\")\n",
        "    samples = rbm.generate_samples(n_samples, k)\n",
        "    samples = samples.reshape((-1, 28, 28))\n",
        "    fig, axes = plt.subplots(1, n_samples, figsize=(15, 3))\n",
        "    for i, ax in enumerate(axes):\n",
        "        ax.imshow(samples[i], cmap='binary')\n",
        "        ax.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "XJXN0zAhjN0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k in k_values:\n",
        "    show_generated_samples(rbms[k], k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "kGXVlQLBjXG8",
        "outputId": "a9ceda95-e1df-4664-b47b-7c4ffcd92d2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated samples for k=1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x300 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated samples for k=3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x300 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated samples for k=5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x300 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q_3"
      ],
      "metadata": {
        "id": "-wCVRr38jacf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_mcmc_process(rbm, n_samples=5, k=5):\n",
        "    \"\"\"\n",
        "    Visualize the MCMC process in RBM (v_0, v_1, ..., v_k).\n",
        "    \"\"\"\n",
        "    samples = np.random.rand(n_samples, rbm.n_visible)  # Random initialization\n",
        "    process = [samples]  # Store intermediate states\n",
        "\n",
        "    # Perform Gibbs sampling for k steps and store each step\n",
        "    for _ in range(k):\n",
        "        h_prob = rbm.sigmoid(np.dot(samples, rbm.W) + rbm.h_bias)\n",
        "        h_sample = rbm.sample(h_prob)\n",
        "        v_prob = rbm.sigmoid(np.dot(h_sample, rbm.W.T) + rbm.v_bias)\n",
        "        samples = rbm.sample(v_prob)\n",
        "        process.append(samples)\n",
        "\n",
        "    # Visualize the process for each sample\n",
        "    fig, axes = plt.subplots(n_samples, k + 1, figsize=(15, n_samples * 2))\n",
        "    for i in range(n_samples):\n",
        "        for j in range(k + 1):\n",
        "            ax = axes[i, j] if n_samples > 1 else axes[j]\n",
        "            ax.imshow(process[j][i].reshape(28, 28), cmap='binary')\n",
        "            ax.axis('off')\n",
        "            if i == 0:\n",
        "                ax.set_title(f\"v_{j}\", fontsize=10)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualize the MCMC process for k=5 with the trained RBM (k=1)\n",
        "visualize_mcmc_process(rbms[1], n_samples=5, k=5)"
      ],
      "metadata": {
        "id": "_22M1AHujZ8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q_4"
      ],
      "metadata": {
        "id": "uP4dbHDfk_Jz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConditionalRBM(RBM):\n",
        "    def __init__(self, n_visible, n_hidden, n_classes):\n",
        "        super().__init__(n_visible + n_classes, n_hidden)\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "    def train(self, data, labels, epochs=10, k=1, lr=0.01, batch_size=64):\n",
        "        data_with_labels = np.hstack([data, labels])  # Append class labels\n",
        "        super().train(data_with_labels, epochs, k, lr, batch_size)\n",
        "\n",
        "    def generate_samples(self, target_label, n_samples=10, k=1):\n",
        "        # Initialize samples and set target label\n",
        "        samples = np.random.rand(n_samples, self.n_visible)\n",
        "        labels = np.zeros((n_samples, self.n_classes))\n",
        "        labels[np.arange(n_samples), target_label] = 1\n",
        "        samples_with_labels = np.hstack([samples, labels])\n",
        "\n",
        "        # Perform Gibbs sampling\n",
        "        generated = self.gibbs_sampling(samples_with_labels, k)\n",
        "        return generated[:, :-self.n_classes]  # Return only the visible units\n",
        "\n",
        "# Prepare one-hot encoded labels\n",
        "n_classes = 10\n",
        "y_train_one_hot = np.eye(n_classes)[y_train]  # Convert labels to one-hot\n",
        "\n",
        "# Train a conditional RBM\n",
        "conditional_rbm = ConditionalRBM(n_visible, n_hidden, n_classes)\n",
        "print(\"Training Conditional RBM...\")\n",
        "conditional_rbm.train(x_train, y_train_one_hot, epochs=5, k=1, lr=0.01, batch_size=64)\n",
        "\n",
        "# Generate samples for specific digits\n",
        "target_digits = [0, 1]  # Digits to generate\n",
        "for digit in target_digits:\n",
        "    print(f\"Generated samples for digit {digit}:\")\n",
        "    generated_samples = conditional_rbm.generate_samples(target_label=digit, n_samples=5, k=5)\n",
        "    generated_samples = generated_samples.reshape((-1, 28, 28))\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
        "    for i, ax in enumerate(axes):\n",
        "        ax.imshow(generated_samples[i], cmap='binary')\n",
        "        ax.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "HCJKmhH_lAXp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}